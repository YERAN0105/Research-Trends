{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 1: Pre-processing - Cell-by-Cell Code",
   "id": "2037aa3d98a47218"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  Import Required Libraries",
   "id": "7be62b8084232d69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T09:54:54.376883Z",
     "start_time": "2025-12-13T09:54:53.993173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ],
   "id": "9917bcb2d224706e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load All CSV Files",
   "id": "58ff2747ee88bc95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T09:55:48.912332Z",
     "start_time": "2025-12-13T09:55:47.789578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load all 12 CSV files\n",
    "property_basic = pd.read_csv('./raw_data/1 - Propery_Basic.csv')\n",
    "property_address = pd.read_csv('./raw_data/2 - Property_Address.csv')\n",
    "property_features = pd.read_csv('./raw_data/3 - Property_Features.csv')\n",
    "picture = pd.read_csv('./raw_data/4 - Picture.csv')\n",
    "sa1_statistics = pd.read_csv('./raw_data/5 - SA1_Satistics.csv')\n",
    "mapping_sa1 = pd.read_csv('./raw_data/6 - Mapping_SA1.csv')\n",
    "school = pd.read_csv('./raw_data/7 - School .csv')\n",
    "school_ranking = pd.read_csv('./raw_data/8 - School ranking.csv')\n",
    "mapping_school = pd.read_csv('./raw_data/9 - Mapping_School.csv')\n",
    "train_station = pd.read_csv('./raw_data/10 - Train_Station.csv')\n",
    "train_time = pd.read_csv('./raw_data/11 - Train_Time.csv')\n",
    "mapping_train = pd.read_csv('./raw_data/12 - Mapping_Train_Station.csv')\n",
    "\n",
    "print(\"All files loaded successfully!\")\n",
    "print(f\"Property Basic shape: {property_basic.shape}\")\n",
    "print(f\"Property Address shape: {property_address.shape}\")\n",
    "print(f\"Property Features shape: {property_features.shape}\")\n"
   ],
   "id": "1875b5257274e283",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files loaded successfully!\n",
      "Property Basic shape: (53220, 13)\n",
      "Property Address shape: (52918, 7)\n",
      "Property Features shape: (53204, 36)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Explore and Check Data Quality",
   "id": "b2129008e9c4a8e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T09:56:19.615109Z",
     "start_time": "2025-12-13T09:56:19.587602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for missing values in key datasets\n",
    "print(\"=== Missing Values in Property Basic ===\")\n",
    "print(property_basic.isnull().sum())\n",
    "print(\"\\n=== Missing Values in Property Address ===\")\n",
    "print(property_address.isnull().sum())\n",
    "print(\"\\n=== Data Types ===\")\n",
    "print(property_basic.dtypes)\n"
   ],
   "id": "54b7359e2798ced4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Missing Values in Property Basic ===\n",
      "ID             0\n",
      "address        0\n",
      "price          0\n",
      "bedroom        0\n",
      "bathroom       0\n",
      "parking        0\n",
      "proType        0\n",
      "sold_date      0\n",
      "agency_name    0\n",
      "agency_addr    0\n",
      "des_head       0\n",
      "des_content    0\n",
      "features       0\n",
      "dtype: int64\n",
      "\n",
      "=== Missing Values in Property Address ===\n",
      "ID                  0\n",
      "Lat                 0\n",
      "Lng                 0\n",
      "Formated_Address    0\n",
      "Locality            0\n",
      "State               0\n",
      "Postal Code         0\n",
      "dtype: int64\n",
      "\n",
      "=== Data Types ===\n",
      "ID              int64\n",
      "address        object\n",
      "price           int64\n",
      "bedroom         int64\n",
      "bathroom        int64\n",
      "parking         int64\n",
      "proType        object\n",
      "sold_date      object\n",
      "agency_name    object\n",
      "agency_addr    object\n",
      "des_head       object\n",
      "des_content    object\n",
      "features       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean Property Basic Data",
   "id": "eb36713cae405354"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T09:56:56.425398Z",
     "start_time": "2025-12-13T09:56:56.344691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean property_basic dataset\n",
    "property_basic_clean = property_basic.copy()\n",
    "\n",
    "# Convert sold_date to datetime\n",
    "property_basic_clean['sold_date'] = pd.to_datetime(property_basic_clean['sold_date'], errors='coerce')\n",
    "\n",
    "# Extract temporal features\n",
    "property_basic_clean['sold_year'] = property_basic_clean['sold_date'].dt.year\n",
    "property_basic_clean['sold_month'] = property_basic_clean['sold_date'].dt.month\n",
    "property_basic_clean['sold_quarter'] = property_basic_clean['sold_date'].dt.quarter\n",
    "\n",
    "# Handle missing values in numerical columns\n",
    "property_basic_clean['bedroom'] = property_basic_clean['bedroom'].fillna(property_basic_clean['bedroom'].median())\n",
    "property_basic_clean['bathroom'] = property_basic_clean['bathroom'].fillna(property_basic_clean['bathroom'].median())\n",
    "property_basic_clean['parking'] = property_basic_clean['parking'].fillna(0)\n",
    "\n",
    "# Handle missing values in categorical columns\n",
    "property_basic_clean['proType'] = property_basic_clean['proType'].fillna('Unknown')\n",
    "\n",
    "# Fill missing text fields with empty string\n",
    "text_columns = ['address', 'des_head', 'des_content', 'features', 'agency_name', 'agency_addr']\n",
    "for col in text_columns:\n",
    "    if col in property_basic_clean.columns:\n",
    "        property_basic_clean[col] = property_basic_clean[col].fillna('')\n",
    "\n",
    "print(\"Property Basic data cleaned!\")\n",
    "print(f\"Shape: {property_basic_clean.shape}\")\n",
    "print(f\"Date range: {property_basic_clean['sold_date'].min()} to {property_basic_clean['sold_date'].max()}\")\n"
   ],
   "id": "35474c85120b3461",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property Basic data cleaned!\n",
      "Shape: (53220, 16)\n",
      "Date range: 2013-01-02 00:00:00 to 2015-10-30 00:00:00\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  Clean Property Address Data",
   "id": "58a9f95f20522a1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T09:57:11.398605Z",
     "start_time": "2025-12-13T09:57:11.378609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean property_address dataset\n",
    "property_address_clean = property_address.copy()\n",
    "\n",
    "# Handle missing coordinates\n",
    "property_address_clean['Lat'] = property_address_clean['Lat'].fillna(property_address_clean['Lat'].median())\n",
    "property_address_clean['Lng'] = property_address_clean['Lng'].fillna(property_address_clean['Lng'].median())\n",
    "\n",
    "# Fill missing text fields\n",
    "for col in ['Formated_Address', 'Locality', 'State', 'Postal Code']:\n",
    "    if col in property_address_clean.columns:\n",
    "        property_address_clean[col] = property_address_clean[col].fillna('')\n",
    "\n",
    "print(\"Property Address data cleaned!\")\n",
    "print(f\"Shape: {property_address_clean.shape}\")\n"
   ],
   "id": "c0a4c123b31434d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property Address data cleaned!\n",
      "Shape: (52918, 7)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean Property Features Data",
   "id": "28ffa0280c168d96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T09:57:19.526419Z",
     "start_time": "2025-12-13T09:57:19.145402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean property_features dataset\n",
    "property_features_clean = property_features.copy()\n",
    "\n",
    "# Get all feature columns (excluding ID)\n",
    "feature_columns = [col for col in property_features_clean.columns if col != 'ID']\n",
    "\n",
    "# Fill missing values with 0 (assuming absence of feature)\n",
    "for col in feature_columns:\n",
    "    property_features_clean[col] = property_features_clean[col].fillna(0)\n",
    "    # Convert to binary (0 or 1)\n",
    "    property_features_clean[col] = property_features_clean[col].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Count total amenities per property\n",
    "property_features_clean['total_amenities'] = property_features_clean[feature_columns].sum(axis=1)\n",
    "\n",
    "print(\"Property Features data cleaned!\")\n",
    "print(f\"Shape: {property_features_clean.shape}\")\n",
    "print(f\"Total feature columns: {len(feature_columns)}\")\n",
    "print(f\"Average amenities per property: {property_features_clean['total_amenities'].mean():.2f}\")\n"
   ],
   "id": "991f44004415b54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property Features data cleaned!\n",
      "Shape: (53204, 37)\n",
      "Total feature columns: 35\n",
      "Average amenities per property: 7.10\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean SA1 Statistics Data",
   "id": "c30832bb13fce99c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T09:57:24.867173Z",
     "start_time": "2025-12-13T09:57:24.858123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean sa1_statistics dataset\n",
    "sa1_statistics_clean = sa1_statistics.copy()\n",
    "\n",
    "# Handle missing values in numerical columns with median\n",
    "numerical_cols = sa1_statistics_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['region_id', 'SA1_ID']]\n",
    "\n",
    "for col in numerical_cols:\n",
    "    sa1_statistics_clean[col] = sa1_statistics_clean[col].fillna(sa1_statistics_clean[col].median())\n",
    "\n",
    "print(\"SA1 Statistics data cleaned!\")\n",
    "print(f\"Shape: {sa1_statistics_clean.shape}\")\n",
    "print(f\"Numerical columns cleaned: {len(numerical_cols)}\")\n"
   ],
   "id": "a84a50409563f5a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA1 Statistics data cleaned!\n",
      "Shape: (13339, 14)\n",
      "Numerical columns cleaned: 12\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean School Data",
   "id": "35cb6eb66bdecf7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T09:57:32.603871Z",
     "start_time": "2025-12-13T09:57:32.596864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean school dataset\n",
    "school_clean = school.copy()\n",
    "\n",
    "# Handle missing values\n",
    "school_clean['gender'] = school_clean['gender'].fillna('Coed')\n",
    "school_clean['restrictedZone'] = school_clean['restrictedZone'].fillna(0)\n",
    "school_clean['type'] = school_clean['type'].fillna('Unknown')\n",
    "school_clean['name'] = school_clean['name'].fillna('')\n",
    "\n",
    "# Handle coordinates\n",
    "school_clean['Lat'] = school_clean['Lat'].fillna(school_clean['Lat'].median())\n",
    "school_clean['Lng'] = school_clean['Lng'].fillna(school_clean['Lng'].median())\n",
    "\n",
    "print(\"School data cleaned!\")\n",
    "print(f\"Shape: {school_clean.shape}\")\n"
   ],
   "id": "30ba599281aba809",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "School data cleaned!\n",
      "Shape: (709, 7)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean School Ranking Data",
   "id": "9f7f3286583fc7c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:01:59.654204Z",
     "start_time": "2025-12-13T10:01:59.649154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean school_ranking dataset\n",
    "school_ranking_clean = school_ranking.copy()\n",
    "\n",
    "print(school_ranking_clean.columns.tolist())"
   ],
   "id": "fcdaf815700875e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school_ID', 'oriName', 'Ranking ', 'Locality', 'IB', 'Students Enrolled in VCE', 'Median VCE score', 'Scores of 40+ (%)']\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:02:00.209693Z",
     "start_time": "2025-12-13T10:02:00.204694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "school_ranking_clean.columns = school_ranking_clean.columns.str.strip()\n",
    "print(school_ranking_clean.columns.tolist())"
   ],
   "id": "d1d8277ff06e79f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school_ID', 'oriName', 'Ranking', 'Locality', 'IB', 'Students Enrolled in VCE', 'Median VCE score', 'Scores of 40+ (%)']\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:02:00.564516Z",
     "start_time": "2025-12-13T10:02:00.556518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Handle missing values in rankings and scores\n",
    "school_ranking_clean['Ranking'] = school_ranking_clean['Ranking'].fillna(999)  # Low rank for missing\n",
    "school_ranking_clean['IB'] = school_ranking_clean['IB'].fillna(0)\n",
    "school_ranking_clean['Students Enrolled in VCE'] = school_ranking_clean['Students Enrolled in VCE'].fillna(0)\n",
    "school_ranking_clean['Median VCE score'] = school_ranking_clean['Median VCE score'].fillna(school_ranking_clean['Median VCE score'].median())\n",
    "school_ranking_clean['Scores of 40+ (%)'] = school_ranking_clean['Scores of 40+ (%)'].fillna(0)\n",
    "\n",
    "print(\"School Ranking data cleaned!\")\n",
    "print(f\"Shape: {school_ranking_clean.shape}\")\n"
   ],
   "id": "a34932b9178261fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "School Ranking data cleaned!\n",
      "Shape: (191, 8)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean Train Station Data",
   "id": "9945fde38eeed683"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:02:19.558950Z",
     "start_time": "2025-12-13T10:02:19.552950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean train_station dataset\n",
    "train_station_clean = train_station.copy()\n",
    "\n",
    "# Handle missing values\n",
    "train_station_clean['stop_name'] = train_station_clean['stop_name'].fillna('')\n",
    "train_station_clean['stop_short_name'] = train_station_clean['stop_short_name'].fillna('')\n",
    "train_station_clean['Lat'] = train_station_clean['Lat'].fillna(train_station_clean['Lat'].median())\n",
    "train_station_clean['Lng'] = train_station_clean['Lng'].fillna(train_station_clean['Lng'].median())\n",
    "\n",
    "print(\"Train Station data cleaned!\")\n",
    "print(f\"Shape: {train_station_clean.shape}\")\n"
   ],
   "id": "76d8722ae43f3add",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Station data cleaned!\n",
      "Shape: (218, 6)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean Mapping Tables",
   "id": "d09ec39981a9b0a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:02:37.424318Z",
     "start_time": "2025-12-13T10:02:37.413348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean mapping tables - these should generally have no missing values\n",
    "# but we'll check and handle them\n",
    "\n",
    "# Mapping SA1\n",
    "mapping_sa1_clean = mapping_sa1.dropna()\n",
    "\n",
    "# Mapping School\n",
    "mapping_school_clean = mapping_school.dropna()\n",
    "\n",
    "# Mapping Train Station\n",
    "mapping_train_clean = mapping_train.copy()\n",
    "mapping_train_clean['distance_value1'] = mapping_train_clean['distance_value1'].fillna(mapping_train_clean['distance_value1'].median())\n",
    "mapping_train_clean['duration_value1'] = mapping_train_clean['duration_value1'].fillna(mapping_train_clean['duration_value1'].median())\n",
    "\n",
    "print(\"Mapping tables cleaned!\")\n",
    "print(f\"Mapping SA1 shape: {mapping_sa1_clean.shape}\")\n",
    "print(f\"Mapping School shape: {mapping_school_clean.shape}\")\n",
    "print(f\"Mapping Train shape: {mapping_train_clean.shape}\")\n"
   ],
   "id": "faf560865eaa205f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping tables cleaned!\n",
      "Mapping SA1 shape: (52914, 2)\n",
      "Mapping School shape: (52913, 2)\n",
      "Mapping Train shape: (52913, 7)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Data for TEXT EMBEDDINGS",
   "id": "8a07441586da733b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:15:14.573148Z",
     "start_time": "2025-12-13T10:15:13.319759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== TEXT EMBEDDINGS DATA =====\n",
    "# Combine all textual information for each property\n",
    "\n",
    "text_embedding_data = property_basic_clean[['ID', 'address', 'des_head', 'des_content', 'features']].copy()\n",
    "\n",
    "# Merge with address information\n",
    "text_embedding_data = text_embedding_data.merge(\n",
    "    property_address_clean[['ID', 'Formated_Address', 'Locality', 'State', 'Postal Code']], \n",
    "    on='ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add agency information\n",
    "text_embedding_data['agency_name'] = property_basic_clean['agency_name']\n",
    "\n",
    "# Create combined text field for embedding\n",
    "text_embedding_data['combined_text'] = (\n",
    "    text_embedding_data['des_head'].astype(str) + ' ' +\n",
    "    text_embedding_data['des_content'].astype(str) + ' ' +\n",
    "    text_embedding_data['features'].astype(str) + ' ' +\n",
    "    text_embedding_data['Locality'].astype(str) + ' ' +\n",
    "    text_embedding_data['State'].astype(str)\n",
    ")\n",
    "\n",
    "# Clean combined text\n",
    "text_embedding_data['combined_text'] = text_embedding_data['combined_text'].str.strip()\n",
    "\n",
    "# Save for text embeddings\n",
    "text_embedding_data.to_csv('./Data/Text/preprocessed_text_embeddings.csv', index=False)\n",
    "\n",
    "print(\"✓ Text Embedding Data Prepared!\")\n",
    "print(f\"Shape: {text_embedding_data.shape}\")\n",
    "print(f\"Columns: {list(text_embedding_data.columns)}\")\n",
    "print(f\"\\nSample combined text:\")\n",
    "print(text_embedding_data['combined_text'].iloc[0][:200], \"...\")\n"
   ],
   "id": "4b70f7376c5f4f5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Text Embedding Data Prepared!\n",
      "Shape: (53220, 11)\n",
      "Columns: ['ID', 'address', 'des_head', 'des_content', 'features', 'Formated_Address', 'Locality', 'State', 'Postal Code', 'agency_name', 'combined_text']\n",
      "\n",
      "Sample combined text:\n",
      "Farmlet Makeover Established farmlet that has had a major makeover with new kitchen, bathroom, en-suite and family room.  Located only 16Kms from Sale a peaceful rural location is this established pro ...\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Data for IMAGE EMBEDDINGS",
   "id": "c47431f17bac47cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:15:30.698356Z",
     "start_time": "2025-12-13T10:15:30.118014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== IMAGE EMBEDDINGS DATA =====\n",
    "# Prepare image metadata with property information\n",
    "\n",
    "image_embedding_data = picture.copy()\n",
    "\n",
    "# Sort by ID and picNo to maintain order\n",
    "image_embedding_data = image_embedding_data.sort_values(['ID', 'picNo'])\n",
    "\n",
    "# Add property price for reference (target variable)\n",
    "image_embedding_data = image_embedding_data.merge(\n",
    "    property_basic_clean[['ID', 'price', 'proType']], \n",
    "    on='ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add location information\n",
    "image_embedding_data = image_embedding_data.merge(\n",
    "    property_address_clean[['ID', 'Locality']], \n",
    "    on='ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Save for image embeddings\n",
    "image_embedding_data.to_csv('./Data/Image/preprocessed_image_embeddings.csv', index=False)\n",
    "\n",
    "print(\"✓ Image Embedding Data Prepared!\")\n",
    "print(f\"Shape: {image_embedding_data.shape}\")\n",
    "print(f\"Columns: {list(image_embedding_data.columns)}\")\n",
    "print(f\"Total properties with images: {image_embedding_data['ID'].nunique()}\")\n",
    "print(f\"Average images per property: {image_embedding_data.groupby('ID').size().mean():.2f}\")\n"
   ],
   "id": "e93e4bb45dd151cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Image Embedding Data Prepared!\n",
      "Shape: (262179, 6)\n",
      "Columns: ['ID', 'picNo', 'picAddr', 'price', 'proType', 'Locality']\n",
      "Total properties with images: 53220\n",
      "Average images per property: 4.93\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Data for GRAPH EMBEDDINGS - Part 1 (Node Features)",
   "id": "14a5c0314980df51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:06:25.716985Z",
     "start_time": "2025-12-13T10:06:25.620565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== GRAPH EMBEDDINGS DATA =====\n",
    "# Prepare comprehensive graph structure with nodes and edges\n",
    "\n",
    "# Start with core property features\n",
    "graph_nodes_properties = property_basic_clean[[\n",
    "    'ID', 'bedroom', 'bathroom', 'parking', 'proType', \n",
    "    'sold_year', 'sold_month', 'sold_quarter', 'price'\n",
    "]].copy()\n",
    "\n",
    "# Add location features\n",
    "graph_nodes_properties = graph_nodes_properties.merge(\n",
    "    property_address_clean[['ID', 'Lat', 'Lng', 'Locality', 'State', 'Postal Code']], \n",
    "    on='ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add all amenity features\n",
    "graph_nodes_properties = graph_nodes_properties.merge(\n",
    "    property_features_clean, \n",
    "    on='ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add SA1 statistics\n",
    "graph_nodes_properties = graph_nodes_properties.merge(\n",
    "    mapping_sa1_clean, \n",
    "    on='ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "graph_nodes_properties = graph_nodes_properties.merge(\n",
    "    sa1_statistics_clean, \n",
    "    on='SA1_ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"✓ Graph Node Features (Properties) Prepared!\")\n",
    "print(f\"Shape: {graph_nodes_properties.shape}\")\n",
    "print(f\"Total features per property: {graph_nodes_properties.shape[1]}\")\n"
   ],
   "id": "f65f01e6f1006d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Graph Node Features (Properties) Prepared!\n",
      "Shape: (53220, 64)\n",
      "Total features per property: 64\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Data for GRAPH EMBEDDINGS - Part 2 (School Nodes)",
   "id": "c50e34e7222a0ed2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:07:08.981216Z",
     "start_time": "2025-12-13T10:07:08.974217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare school nodes with rankings\n",
    "graph_nodes_schools = school_clean.merge(\n",
    "    school_ranking_clean, \n",
    "    on='school_ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing rankings\n",
    "graph_nodes_schools['Ranking'] = graph_nodes_schools['Ranking'].fillna(999)\n",
    "graph_nodes_schools['Median VCE score'] = graph_nodes_schools['Median VCE score'].fillna(\n",
    "    graph_nodes_schools['Median VCE score'].median()\n",
    ")\n",
    "\n",
    "print(\"✓ Graph Node Features (Schools) Prepared!\")\n",
    "print(f\"Shape: {graph_nodes_schools.shape}\")\n",
    "print(f\"Columns: {list(graph_nodes_schools.columns)}\")\n"
   ],
   "id": "2a0c98d541bf9a19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Graph Node Features (Schools) Prepared!\n",
      "Shape: (709, 14)\n",
      "Columns: ['school_ID', 'name', 'gender', 'restrictedZone', 'type', 'Lng', 'Lat', 'oriName', 'Ranking', 'Locality', 'IB', 'Students Enrolled in VCE', 'Median VCE score', 'Scores of 40+ (%)']\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Data for GRAPH EMBEDDINGS - Part 3 (Train Station Nodes)",
   "id": "3af4f305419069d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:11:29.734947Z",
     "start_time": "2025-12-13T10:11:29.729948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare train station nodes\n",
    "graph_nodes_stations = train_station_clean.copy()\n",
    "\n",
    "print(\"✓ Graph Node Features (Train Stations) Prepared!\")\n",
    "print(f\"Shape: {graph_nodes_stations.shape}\")\n",
    "print(f\"Columns: {list(graph_nodes_stations.columns)}\")\n"
   ],
   "id": "7babcdbe2b3899af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Graph Node Features (Train Stations) Prepared!\n",
      "Shape: (218, 6)\n",
      "Columns: ['stop_id', 'stop_no', 'stop_short_name', 'stop_name', 'Lat', 'Lng']\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Data for GRAPH EMBEDDINGS - Part 4 (Property-School Edges)",
   "id": "ab837612d294d31e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:11:43.722621Z",
     "start_time": "2025-12-13T10:11:43.714625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare edges: Property to School relationships\n",
    "graph_edges_property_school = mapping_school_clean.copy()\n",
    "graph_edges_property_school['edge_type'] = 'property_to_school'\n",
    "\n",
    "# Add school rankings to edges\n",
    "graph_edges_property_school = graph_edges_property_school.merge(\n",
    "    school_ranking_clean[['school_ID', 'Ranking', 'Median VCE score']], \n",
    "    on='school_ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"✓ Graph Edges (Property-School) Prepared!\")\n",
    "print(f\"Shape: {graph_edges_property_school.shape}\")\n",
    "print(f\"Total property-school connections: {len(graph_edges_property_school)}\")\n"
   ],
   "id": "fd2b2e8bb4b0c302",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Graph Edges (Property-School) Prepared!\n",
      "Shape: (52913, 5)\n",
      "Total property-school connections: 52913\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Data for GRAPH EMBEDDINGS - Part 5 (Property-Station Edges)",
   "id": "96c236c562674e12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:11:59.255112Z",
     "start_time": "2025-12-13T10:11:59.247112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare edges: Property to Train Station relationships\n",
    "graph_edges_property_station = mapping_train_clean[['ID', 'stop_id', 'distance_value1', 'duration_value1']].copy()\n",
    "graph_edges_property_station['edge_type'] = 'property_to_station'\n",
    "\n",
    "# Rename columns for consistency\n",
    "graph_edges_property_station.rename(columns={\n",
    "    'distance_value1': 'distance_meters',\n",
    "    'duration_value1': 'duration_seconds'\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"✓ Graph Edges (Property-Station) Prepared!\")\n",
    "print(f\"Shape: {graph_edges_property_station.shape}\")\n",
    "print(f\"Total property-station connections: {len(graph_edges_property_station)}\")\n"
   ],
   "id": "639ebfb14ecc6cc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Graph Edges (Property-Station) Prepared!\n",
      "Shape: (52913, 5)\n",
      "Total property-station connections: 52913\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Data for GRAPH EMBEDDINGS - Part 6 (Station-Station Edges)",
   "id": "a40cf08b97d98429"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:12:13.445775Z",
     "start_time": "2025-12-13T10:12:13.439774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare edges: Train Station to Train Station relationships (connectivity)\n",
    "graph_edges_station_station = train_time.copy()\n",
    "graph_edges_station_station['edge_type'] = 'station_to_station'\n",
    "\n",
    "# Rename columns for consistency\n",
    "graph_edges_station_station.rename(columns={\n",
    "    'stop_ori': 'source_station',\n",
    "    'stop_des': 'target_station',\n",
    "    'avg_time': 'travel_time_minutes',\n",
    "    'trans_flag': 'requires_transfer'\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"✓ Graph Edges (Station-Station) Prepared!\")\n",
    "print(f\"Shape: {graph_edges_station_station.shape}\")\n",
    "print(f\"Total station connections: {len(graph_edges_station_station)}\")\n"
   ],
   "id": "c675d813521e0d84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Graph Edges (Station-Station) Prepared!\n",
      "Shape: (47524, 6)\n",
      "Total station connections: 47524\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save All Graph Embedding Files",
   "id": "570ff08b54b2406e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:14:04.191926Z",
     "start_time": "2025-12-13T10:14:03.135171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save all graph-related files\n",
    "graph_nodes_properties.to_csv('./Data/Graphs/graph_nodes_properties.csv', index=False)\n",
    "graph_nodes_schools.to_csv('./Data/Graphs/graph_nodes_schools.csv', index=False)\n",
    "graph_nodes_stations.to_csv('./Data/Graphs/graph_nodes_stations.csv', index=False)\n",
    "graph_edges_property_school.to_csv('./Data/Graphs/graph_edges_property_school.csv', index=False)\n",
    "graph_edges_property_station.to_csv('./Data/Graphs/graph_edges_property_station.csv', index=False)\n",
    "graph_edges_station_station.to_csv('./Data/Graphs/graph_edges_station_station.csv', index=False)\n",
    "\n",
    "print(\"✓ All Graph Embedding Files Saved!\")\n",
    "print(\"\\nGraph Files Created:\")\n",
    "print(\"  1. graph_nodes_properties.csv\")\n",
    "print(\"  2. graph_nodes_schools.csv\")\n",
    "print(\"  3. graph_nodes_stations.csv\")\n",
    "print(\"  4. graph_edges_property_school.csv\")\n",
    "print(\"  5. graph_edges_property_station.csv\")\n",
    "print(\"  6. graph_edges_station_station.csv\")\n"
   ],
   "id": "dec2718df20be83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All Graph Embedding Files Saved!\n",
      "\n",
      "Graph Files Created:\n",
      "  1. graph_nodes_properties.csv\n",
      "  2. graph_nodes_schools.csv\n",
      "  3. graph_nodes_stations.csv\n",
      "  4. graph_edges_property_school.csv\n",
      "  5. graph_edges_property_station.csv\n",
      "  6. graph_edges_station_station.csv\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create Summary Report",
   "id": "29f95091b073bbf2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T10:17:20.775044Z",
     "start_time": "2025-12-13T10:17:20.749045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create comprehensive preprocessing summary\n",
    "print(\"=\" * 80)\n",
    "print(\"PREPROCESSING SUMMARY - PROPERTY VALUATION PREDICTION SYSTEM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nDATASET OVERVIEW\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total Properties: {property_basic_clean['ID'].nunique()}\")\n",
    "print(f\"Price Range: ${property_basic_clean['price'].min():,.0f} - ${property_basic_clean['price'].max():,.0f}\")\n",
    "print(f\"Average Price: ${property_basic_clean['price'].mean():,.0f}\")\n",
    "print(f\"Median Price: ${property_basic_clean['price'].median():,.0f}\")\n",
    "\n",
    "print(\"\\nTEXT EMBEDDINGS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"File: preprocessed_text_embeddings.csv\")\n",
    "print(f\"Records: {len(text_embedding_data)}\")\n",
    "print(f\"Columns: {text_embedding_data.shape[1]}\")\n",
    "print(f\"Key Fields: address, des_head, des_content, features, combined_text\")\n",
    "\n",
    "print(\"\\nIMAGE EMBEDDINGS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"File: preprocessed_image_embeddings.csv\")\n",
    "print(f\"Total Images: {len(image_embedding_data)}\")\n",
    "print(f\"Properties with Images: {image_embedding_data['ID'].nunique()}\")\n",
    "print(f\"Avg Images per Property: {image_embedding_data.groupby('ID').size().mean():.2f}\")\n",
    "\n",
    "print(\"\\nGRAPH EMBEDDINGS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Property Nodes: {len(graph_nodes_properties)}\")\n",
    "print(f\"School Nodes: {len(graph_nodes_schools)}\")\n",
    "print(f\"Station Nodes: {len(graph_nodes_stations)}\")\n",
    "print(f\"Property-School Edges: {len(graph_edges_property_school)}\")\n",
    "print(f\"Property-Station Edges: {len(graph_edges_property_station)}\")\n",
    "print(f\"Station-Station Edges: {len(graph_edges_station_station)}\")\n",
    "print(f\"Total Graph Features per Property: {graph_nodes_properties.shape[1]}\")\n",
    "\n",
    "print(\"\\nPREPROCESSING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  → Step 2: Create Graph Embeddings using graph_*.csv files\")\n",
    "print(\"  → Step 3: Create Text Embeddings using preprocessed_text_embeddings.csv\")\n",
    "print(\"  → Step 4: Create Image Embeddings using preprocessed_image_embeddings.csv\")\n",
    "print(\"  → Step 5: Combine all embeddings and train prediction model\")\n"
   ],
   "id": "da36d1690c8f5bfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPROCESSING SUMMARY - PROPERTY VALUATION PREDICTION SYSTEM\n",
      "================================================================================\n",
      "\n",
      "DATASET OVERVIEW\n",
      "--------------------------------------------------------------------------------\n",
      "Total Properties: 53220\n",
      "Price Range: $11,562 - $123,456,792\n",
      "Average Price: $707,975\n",
      "Median Price: $610,000\n",
      "\n",
      "TEXT EMBEDDINGS\n",
      "--------------------------------------------------------------------------------\n",
      "File: preprocessed_text_embeddings.csv\n",
      "Records: 53220\n",
      "Columns: 11\n",
      "Key Fields: address, des_head, des_content, features, combined_text\n",
      "\n",
      "IMAGE EMBEDDINGS\n",
      "--------------------------------------------------------------------------------\n",
      "File: preprocessed_image_embeddings.csv\n",
      "Total Images: 262179\n",
      "Properties with Images: 53220\n",
      "Avg Images per Property: 4.93\n",
      "\n",
      "GRAPH EMBEDDINGS\n",
      "--------------------------------------------------------------------------------\n",
      "Property Nodes: 53220\n",
      "School Nodes: 709\n",
      "Station Nodes: 218\n",
      "Property-School Edges: 52913\n",
      "Property-Station Edges: 52913\n",
      "Station-Station Edges: 47524\n",
      "Total Graph Features per Property: 64\n",
      "\n",
      "PREPROCESSING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Next Steps:\n",
      "  → Step 2: Create Graph Embeddings using graph_*.csv files\n",
      "  → Step 3: Create Text Embeddings using preprocessed_text_embeddings.csv\n",
      "  → Step 4: Create Image Embeddings using preprocessed_image_embeddings.csv\n",
      "  → Step 5: Combine all embeddings and train prediction model\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9e9c347cd5ec6875"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
